{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio pydub sarvamai\n",
        "\n",
        "import gradio as gr\n",
        "from pydub import AudioSegment\n",
        "import tempfile, base64, traceback\n",
        "from sarvamai import SarvamAI\n"
      ],
      "metadata": {
        "id": "w9GbDRg2uOjv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "from sarvamai import SarvamAI\n",
        "from sarvamai.play import save\n",
        "SARVAM_API_KEY = getpass.getpass(\"ğŸ”‘ Enter your Sarvam API key: \")\n",
        "client = SarvamAI(api_subscription_key=SARVAM_API_KEY)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAxX1nM4Auow",
        "outputId": "27e0980f-8814-4de9-be40-5f0e20d81bdb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”‘ Enter your Sarvam API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "i5znT1lZqPJb",
        "outputId": "2519f7ac-8e4f-4ba1-8920-3e6fad718544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3367980720.py:102: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=500, label=\"ğŸ™ï¸ Voice Conversation\", show_label=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7964bda788c88bc78e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7964bda788c88bc78e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "conversation_history = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a friendly, bilingual voice assistant that replies naturally and politely.\"}\n",
        "]\n",
        "\n",
        "def voice_chat(audio_file, chat_history):\n",
        "    global conversation_history\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        audio = audio.set_frame_rate(16000).set_channels(1)\n",
        "        audio.export(\"input.wav\", format=\"wav\")\n",
        "        print(\"ğŸ§ Converted to input.wav\")\n",
        "\n",
        "        stt = client.speech_to_text.transcribe(\n",
        "            file=open(\"input.wav\", \"rb\"),\n",
        "            model=\"saarika:v2.5\",\n",
        "            language_code=\"unknown\"\n",
        "        )\n",
        "        detected_lang = getattr(stt, \"language_code\", None) or \"en-IN\"\n",
        "        if detected_lang == \"unknown\":\n",
        "            detected_lang = \"en-IN\"\n",
        "\n",
        "        print(\"ğŸ§¾ STT response:\", stt)\n",
        "\n",
        "        transcript = \"\"\n",
        "        if hasattr(stt, \"text\"):\n",
        "            transcript = stt.text\n",
        "        elif hasattr(stt, \"transcript\"):\n",
        "            transcript = stt.transcript\n",
        "        elif isinstance(stt, dict):\n",
        "            transcript = stt.get(\"text\") or stt.get(\"transcript\", \"\")\n",
        "        transcript = (transcript or \"\").strip()\n",
        "\n",
        "        if not transcript:\n",
        "            chat_history += [[\"âŒ Couldn't understand audio.\", None]]\n",
        "            return chat_history, None\n",
        "\n",
        "        print(\"ğŸ—£ï¸ User said:\", transcript)\n",
        "\n",
        "        conversation_history.append({\"role\": \"user\", \"content\": transcript})\n",
        "        chat_response = client.chat.completions(\n",
        "            messages=conversation_history,\n",
        "            temperature=0.5,\n",
        "            top_p=1,\n",
        "            max_tokens=1000,\n",
        "        )\n",
        "        reply = chat_response.choices[0].message.content\n",
        "        conversation_history.append({\"role\": \"assistant\", \"content\": reply})\n",
        "\n",
        "        if len(conversation_history) > 7:\n",
        "            conversation_history = [conversation_history[0]] + conversation_history[-6:]\n",
        "\n",
        "        tts_response = client.text_to_speech.convert(\n",
        "            target_language_code= detected_lang,\n",
        "            text=reply,\n",
        "            model=\"bulbul:v2\",\n",
        "            speaker=\"anushka\"\n",
        "        )\n",
        "\n",
        "        if hasattr(tts_response, \"audios\") and len(tts_response.audios) > 0:\n",
        "            audio_base64 = tts_response.audios[0]\n",
        "            tts_audio = base64.b64decode(audio_base64)\n",
        "        else:\n",
        "            chat_history += [[f\"âŒ TTS failed: {tts_response}\", None]]\n",
        "            return chat_history, None\n",
        "\n",
        "        tts_path = tempfile.mktemp(suffix=\".wav\")\n",
        "        with open(tts_path, \"wb\") as f:\n",
        "            f.write(tts_audio)\n",
        "\n",
        "        chat_history.append((\n",
        "        gr.Audio(audio_file, label=\"ğŸ¤ You\"),\n",
        "        gr.Audio(tts_path, label=\"ğŸ¤– AI\")\n",
        "))\n",
        "\n",
        "        return chat_history, tts_path\n",
        "\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        chat_history += [[f\"âŒ Error: {str(e)}\", None]]\n",
        "        return chat_history, None\n",
        "\n",
        "def end_conversation():\n",
        "    global conversation_history\n",
        "    conversation_history = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a friendly, bilingual voice assistant that replies naturally and politely.\"}\n",
        "    ]\n",
        "    return [], None\n",
        "\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        <div style='text-align:center;'>\n",
        "        <h2>ğŸ’¬ Indic Voice Conversational Agent</h2>\n",
        "        <p>ğŸ™ï¸ Send a voice note â€” get a voice reply back!</p>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            chatbot = gr.Chatbot(height=500, label=\"ğŸ™ï¸ Voice Conversation\", show_label=True)\n",
        "        with gr.Column(scale=1):\n",
        "            mic = gr.Audio(type=\"filepath\", label=\"ğŸ¤ Record your voice note\")\n",
        "            audio_out = gr.Audio(label=\"ğŸ”Š Model reply playback\")\n",
        "\n",
        "    with gr.Row():\n",
        "        send_btn = gr.Button(\"Send Voice Note\")\n",
        "        end_btn = gr.Button(\"End Conversation\")\n",
        "\n",
        "    send_btn.click(fn=voice_chat, inputs=[mic, chatbot], outputs=[chatbot, audio_out])\n",
        "    end_btn.click(fn=end_conversation, outputs=[chatbot, audio_out])\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}